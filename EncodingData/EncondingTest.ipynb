{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# This notebook test self encoding"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from QuotesDownloader import SoftfxDownloader, QuotesType, QuotesPeriodicity\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.utils import plot_model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plan:\n",
    "1. Download data for EURUSD\n",
    "2. Convert data to pips\n",
    "3. Convert bar prices to one pip movement. If bid was increased to X pips, X ones will be generated.\n",
    "4. Create network for encoding/decoding to dictionary.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  First step. Download M1 data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(368053, 6)\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "symbols = [\"EURUSD\"]\n",
    "pips_value = [10**-5]\n",
    "N_x = 1000 #number of pips movements for NN\n",
    "\n",
    "qd = SoftfxDownloader.Downloader()\n",
    "train_raw = qd.get_quotes(symbols[0], datetime.date(2020, 1, 1), datetime.date(2021, 1, 1), QuotesPeriodicity.M1, QuotesType.Bids)\n",
    "train_raw = train_raw.to_numpy()\n",
    "print(train_raw.shape)\n",
    "print(train_raw.dtype)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Second step. Convert data to pips"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "(368053,)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode input data to NN friendly format.\n",
    "bids = train_raw[:,1] / pips_value\n",
    "bids = bids.astype('f')\n",
    "bids = np.rint(bids).astype('i')\n",
    "bids.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "###  Fourth step. Convert to pip steps"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# initializing list\n",
    "def pips2pricemovments(arr : np.ndarray) -> np.ndarray:\n",
    "    d_iter = map(lambda x, y: np.repeat(1, y-x) if x<y else np.repeat(0, x-y), arr[:-1], arr[1:])\n",
    "    return np.concatenate(list(d_iter))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file\n"
     ]
    },
    {
     "data": {
      "text/plain": "(3672304,)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_converted = \"bids_EURUSD.npy\"\n",
    "if os.path.exists(filename_converted):\n",
    "    print(\"Loading file\")\n",
    "    d = np.load(filename_converted)\n",
    "else:\n",
    "    d = pips2pricemovments(bids)\n",
    "    np.save(filename_converted, d)\n",
    "d.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "##  Fifth step. NN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape is (367230,).\n",
      "Test data shape is (3305074,).\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "#train/test split\n",
    "# Test your function and save all \"global\" variables within the G class (G stands for global)\n",
    "@dataclass\n",
    "class GSettings:\n",
    "    filename_converted = \"bids_EURUSD.npy\"\n",
    "    d = np.load(filename_converted)\n",
    "    N = d.shape[0]\n",
    "    train_ratio = 0.1\n",
    "    n_train = int(N * train_ratio)\n",
    "    window_size = 1024\n",
    "    batch_size = 64\n",
    "    SHUFFLE_BUFFER_SIZE = 1000\n",
    "    N_letters = 10\n",
    "\n",
    "train_data = d[:GSettings.n_train]\n",
    "test_data = d[GSettings.n_train:]\n",
    "\n",
    "print(f\"Train data shape is {train_data.shape}.\\nTest data shape is {test_data.shape}.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PetrosyanPC\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def windowed_dataset(series, window_size=GSettings.window_size, batch_size=GSettings.batch_size, shuffle_buffer=GSettings.SHUFFLE_BUFFER_SIZE):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(window_size, shift=1, drop_remainder=True)\n",
    "    ds = ds.flat_map(lambda window: window.batch(window_size))\n",
    "    ds = ds.shuffle(shuffle_buffer)\n",
    "    ds = ds.map(lambda w: (w, w))\n",
    "    ds = ds.batch(batch_size)#.prefetch(1)\n",
    "    #ds = ds.map(lambda x, y: (x, tf.squeeze(y, axis=-1)))\n",
    "    #for window in ds:\n",
    "     #  print(list(window))\n",
    "    return ds\n",
    "\n",
    "train_set = windowed_dataset(train_data)\n",
    "test_set = windowed_dataset(test_data)\n",
    "\n",
    "#t = train_set.take(1)\n",
    "#list(t.as_numpy_iterator())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class Alphabet(Model):\n",
    "    def __init__(self):\n",
    "        super(Alphabet, self).__init__()\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(GSettings.window_size, 1)),\n",
    "            layers.Conv1D(2, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(4, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(8, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(16, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(32, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Flatten()\n",
    "            ,layers.Dense(54)\n",
    "        ])\n",
    "        latent_shape = self.encoder.layers[-2].input_shape\n",
    "        print(latent_shape)\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=54),\n",
    "            layers.Dense(latent_shape[1]*latent_shape[2], activation='relu'),\n",
    "            layers.Reshape(latent_shape[1:]),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(32, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(16, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(8, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(4, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(2, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.Conv1D(1, 3, activation = 'sigmoid', padding = 'same')\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class AlphabetMulti(Model):\n",
    "    def __init__(self):\n",
    "        super(AlphabetMulti, self).__init__()\n",
    "        self.nne1 = tf.keras.Sequential([\n",
    "            layers.Input(shape=(GSettings.window_size)),\n",
    "            layers.Conv1D(2, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(4, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(8, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(16, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "            layers.Conv1D(32, 9, activation='relu', padding='same', strides=1),\n",
    "            layers.MaxPool1D(2, strides=2, padding='valid')\n",
    "        ])\n",
    "        nne1_outputshape = self.nne1.layers[-1].output_shape\n",
    "        print(nne1_outputshape)\n",
    "\n",
    "        self.encoder1 = tf.keras.Sequential([\n",
    "            layers.Input(shape=nne1_outputshape[1:]),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(100, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        # self.nne2 = tf.keras.Sequential([\n",
    "        #     layers.Input(shape=nne1_outputshape[1:]),\n",
    "        #     layers.Conv1D(32, 9, activation='relu', padding='same', strides=1),\n",
    "        #     layers.MaxPool1D(2, strides=2, padding='valid'),\n",
    "        #     layers.Conv1D(64, 9, activation='relu', padding='same', strides=1),\n",
    "        #     layers.MaxPool1D(2, strides=2, padding='valid')\n",
    "        # ])\n",
    "        #\n",
    "        # nne2_outputshape = self.nne2.layers[-1].output_shape\n",
    "        # print(nne2_outputshape)\n",
    "        #\n",
    "        # self.encoder2 = tf.keras.Sequential([\n",
    "        #     layers.Input(shape=nne2_outputshape[1:]),\n",
    "        #     layers.Flatten(),\n",
    "        #     layers.Dense(1024, activation='relu'),\n",
    "        #     layers.Dense(100, activation='relu'),\n",
    "        #     layers.Dense(10, activation='sigmoid')\n",
    "        # ])\n",
    "\n",
    "        self.decoder1 = tf.keras.Sequential([\n",
    "            layers.Input(shape=100),\n",
    "            layers.Dense(nne1_outputshape[1]*nne1_outputshape[2], activation='relu'),\n",
    "            layers.Reshape(nne1_outputshape[1:])\n",
    "        ])\n",
    "        self.nnd1 = tf.keras.Sequential([\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(32, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(16, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(8, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(4, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.UpSampling1D(2),\n",
    "            layers.Conv1DTranspose(2, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "            layers.Conv1D(1, 3, activation = 'sigmoid', padding = 'same', name = 'nnd1')\n",
    "        ])\n",
    "        # self.nnd1_ = tf.keras.Sequential([\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(32, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(16, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(8, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(4, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(2, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.Conv1D(1, 3, activation = 'sigmoid', padding = 'same', name = 'nnd1_')\n",
    "        # ])\n",
    "        # self.decoder2 = tf.keras.Sequential([\n",
    "        #     layers.Input(shape=10),\n",
    "        #     layers.Dense(100, activation='relu'),\n",
    "        #     layers.Dense(1024, activation='relu'),\n",
    "        #     layers.Dense(nne2_outputshape[1]*nne2_outputshape[2], activation='relu'),\n",
    "        #     layers.Reshape(nne2_outputshape[1:])\n",
    "        # ])\n",
    "        # self.nnd2 = tf.keras.Sequential([\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(64, kernel_size=9, strides=1, activation='relu', padding='same'),\n",
    "        #     layers.UpSampling1D(2),\n",
    "        #     layers.Conv1DTranspose(32, kernel_size=9, strides=1, activation='relu', padding='same')\n",
    "        # ])\n",
    "\n",
    "    def call(self, x):\n",
    "        nne1_result = self.nne1(x)\n",
    "        encoded1 = self.encoder1(nne1_result)\n",
    "        decoded1 = self.decoder1(encoded1)\n",
    "        decoded1 = self.nnd1(decoded1)\n",
    "\n",
    "        #nne2_result = self.nne2(nne1_result)\n",
    "        #encoded2 = self.encoder2(nne2_result)\n",
    "\n",
    "        #decoded2 = self.decoder2(encoded2)\n",
    "        #decoded2 = self.nnd2(decoded2)\n",
    "        #decoded2 = self.nnd1_(decoded2)\n",
    "\n",
    "        return [decoded1]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "\n",
    "class AlphabetTest(Model):\n",
    "    def __init__(self):\n",
    "        super(AlphabetTest, self).__init__()\n",
    "        self.nne1 = tf.keras.Sequential([\n",
    "            layers.Input(shape=(GSettings.window_size)),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(100, activation='relu')\n",
    "        ])\n",
    "        self.encoder1 = tf.keras.Sequential([\n",
    "            layers.Dense(100, activation='sigmoid')\n",
    "        ])\n",
    "        self.decoder1 = tf.keras.Sequential([\n",
    "            layers.Input(shape=100),\n",
    "            layers.Dense(100, activation='relu')\n",
    "        ])\n",
    "        self.nnd1 = tf.keras.Sequential([\n",
    "            layers.Dense(GSettings.window_size, activation='relu'),\n",
    "            layers.Reshape((GSettings.window_size, 1))\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        nne1_result = self.nne1(x)\n",
    "        encoded1 = self.encoder1(nne1_result)\n",
    "        decoded1 = self.decoder1(encoded1)\n",
    "        decoded1 = self.nnd1(decoded1)\n",
    "\n",
    "        #nne2_result = self.nne2(nne1_result)\n",
    "        #encoded2 = self.encoder2(nne2_result)\n",
    "\n",
    "        #decoded2 = self.decoder2(encoded2)\n",
    "        #decoded2 = self.nnd2(decoded2)\n",
    "        #decoded2 = self.nnd1_(decoded2)\n",
    "\n",
    "        return decoded1\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "autoencoder = AlphabetTest() #AlphabetSimple()\n",
    "#autoencoder.build((GSettings.window_size))\n",
    "#plot_model(autoencoder.nne1, show_shapes=True, show_layer_names=True)\n",
    "#autoencoder.encoder1.summary()\n",
    "#autoencoder.decoder1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# td = np.random.randint(0,2,GSettings.window_size)\n",
    "# td = np.reshape(td, (1, 540, 1))\n",
    "# print(td.shape)\n",
    "# autoencoder.encoder(td)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# td = np.zeros(54)\n",
    "# td[0] = 1\n",
    "# td = td[np.newaxis, :]\n",
    "# autoencoder.decoder(td)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "#autoencoder.nne1.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import sys\n",
    "class CustomMSE(tf.keras.losses.Loss):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        #print(y_true.shape)\n",
    "        #mse1 = tf.reduce_mean(tf.square(y_true[:, 0] - y_pred[:, 0]))\n",
    "        #mse2 = tf.reduce_mean(tf.square(y_true[:, 1] - y_pred[:, 1]))\n",
    "        #total_mse = mse1 + mse2\n",
    "        #return total_mse\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "def custom_loss_function(y_true, y_pred):\n",
    "    tf.print(\"\\n y_true\", y_true, output_stream=sys.stdout)\n",
    "    tf.print(\"\\n y_pred\", y_pred, output_stream=sys.stdout)\n",
    "\n",
    "   # y_true = tf.cast(y_true, tf.float32)\n",
    "    #y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "\n",
    "    #squared_difference = tf.square(y_true - y_pred)\n",
    "    #return tf.reduce_mean(squared_difference)\n",
    "    return tf.square(y_pred)\n",
    "\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy']) #'binary_crossentropy'\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Got an unexpected keyword argument 'param'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[25], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m#from tensorflow.keras.losses import mean_squared_error\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m autoencoder\u001B[38;5;241m.\u001B[39mcompile(loss \u001B[38;5;241m=\u001B[39m \u001B[43mmean_squared_error\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m--> 153\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    154\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    155\u001B[0m   \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\dispatch.py:1170\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m iterable_params \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1169\u001B[0m   args, kwargs \u001B[38;5;241m=\u001B[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001B[1;32m-> 1170\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mapi_dispatcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1171\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mNotImplemented\u001B[39m:\n\u001B[0;32m   1172\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "\u001B[1;31mTypeError\u001B[0m: Got an unexpected keyword argument 'param'"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.losses import mean_squared_error\n",
    "autoencoder.compile(loss = mean_squared_error(param=2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    145/Unknown - 11s 68ms/step - loss: 0.3125 - accuracy: 0.5456"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[90], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mautoencoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_set\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TimeSeries\\lib\\site-packages\\keras\\engine\\training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m   1562\u001B[0m ):\n\u001B[0;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    877\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    879\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[1;32m--> 880\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    882\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[0;32m    883\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    909\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    910\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    911\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 912\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_no_variable_creation_fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    914\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    915\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    916\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001B[0m, in \u001B[0;36mTracingCompiler.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    132\u001B[0m   (concrete_function,\n\u001B[0;32m    133\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m--> 134\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconcrete_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1741\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1743\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1744\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1745\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1746\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1747\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1748\u001B[0m     args,\n\u001B[0;32m   1749\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1750\u001B[0m     executing_eagerly)\n\u001B[0;32m   1751\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    376\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    377\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 378\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    379\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    380\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    381\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    382\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    383\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    386\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    387\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    390\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    391\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(train_set, epochs=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = [0, 1, 0, 0]\n",
    "y_pred = [-18.6, 0.51, 2.94, -12.8]\n",
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "bce(y_true, y_pred).numpy()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
